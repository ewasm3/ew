
# Table of Contents

1.  [Canu assembly](#orge4e2fc3)
2.  [FALCON assembly](#org7429071)
3.  [MECAT assembly](#orga3e5b09)
4.  [Polishing by PacBio reads (for FALCON assembly)](#org5c85570)
    1.  [BLASR mapping](#org233dbd1)
    2.  [Sort and pbindex](#org7f260ec)
    3.  [Run arrow](#org31b74cd)
    4.  [Combine fasta generated by arrow](#orgc0f2f08)
5.  [Polishing by illumina reads (for FALCON assembly)](#orgb93b880)
6.  [Scaffolding by Hi-C reads](#orga5cb8c8)
7.  [Gap closing](#org5ef3756)



<a id="orge4e2fc3"></a>

# Canu assembly

`canu.conf`:

    genomeSize=1g
    java=/mnt/nfs1/software/jre1.8.0_141/bin/java
    gnuplot=/mnt/nfs1/build/gnuplot-5.2.2/bin/gnuplot
    gnuplotImageFormat=svg
    gridEngine=slurm

Run Canu:

    /mnt/nfs1/software/canu/Linux-amd64/bin/canu -s canu.conf -p ew -d /mnt/nfs46/ew/assembly -pacbio-raw data/subreads/*fq.gz


<a id="org7429071"></a>

# FALCON assembly

`ew.cfg`:

    [General]
    # list of files of the initial subread fasta files
    input_fofn = input.fofn

    input_type = raw
    #input_type = preads

    # The length cutoff used for seed reads used for initial mapping
    length_cutoff = 12000

    # The length cutoff used for seed reads usef for pre-assembly
    length_cutoff_pr = 12000

    # Cluster queue setting
    job_type = SLURM
    jobqueue = serial
    sge_option_da = --ntasks 1 --nodes 1 --cpus-per-task 8 --mem 10g --time 00:20:00
    sge_option_la = --ntasks 1 --nodes 1 --cpus-per-task 2 --mem 10g --time 00:05:00
    sge_option_pda = --ntasks 1 --nodes 1 --cpus-per-task 8 --mem 15g --time 00:20:00
    sge_option_pla = --ntasks 1 --nodes 1 --cpus-per-task 2 --mem 10g --time 00:05:00
    sge_option_fc = --ntasks 1 --nodes 1 --cpus-per-task 16 --mem 10g --time 00:20:00
    sge_option_cns = --ntasks 1 --nodes 1 --cpus-per-task 8 --mem 10g --time 00:20:00

    # concurrency settgin
    pa_concurrent_jobs = 24
    cns_concurrent_jobs = 24
    ovlp_concurrent_jobs = 24

    # overlapping options for Daligner
    pa_HPCdaligner_option =  -v -B4 -t16 -e.70 -l1000 -s1000
    ovlp_HPCdaligner_option = -v -B4 -t32 -h60 -e.96 -l500 -s1000

    pa_DBsplit_option = -x500 -s50
    ovlp_DBsplit_option = -x500 -s50

    # error correction consensus optione
    falcon_sense_option = --output_multi --min_idt 0.70 --min_cov 4 --max_n_read 200 --n_core 6

    # overlap filtering options
    overlap_filtering_setting = --max_diff 100 --max_cov 100 --min_cov 20 --bestn 10

Run FALCON:

    fc_run ew.cfg


<a id="orga3e5b09"></a>

# MECAT assembly

    cd /mnt/nfs46/ew/data/subreads/
    # convert fastq to fasta and split to proper size
    for fq in /mnt/nfs46/ew/data/subreads/*.fq.gz; do
        fa=$(echo $fq | sed 's/fq\.gz$/fasta/')
        gzip -dc $fq | perl -wne 's/^@/>/ and $seq=<> and print qq/$_$seq/'
    done | split -l100000 -a3 -d --additional-suffix=.fasta - pb

    fa='/mnt/nfs46/ew/data/subreads/all.fasta'
    cat pb* >$fa
    source /mnt/nfs1/software/MECAT/source.sh
    outdir='/mnt/nfs46/ew/assembly-mecat/run'
    out='ew.pm.can'
    cd $outdir
    ulimit -v 200000000
    /mnt/nfs1/software/MECAT/Linux-amd64/bin/mecat2pw -j 0 -d $fa -o $out -w $outdir -t 48
    out_cns='ew.cns.filtered'
    mecat2cns -i 0 -t 48 $out $fa $out_cns
    out_step3='ew.25x.fasta'
    extract_sequences $out_cns $out_cns 1200000000 25
    mecat2canu -trim-assemble -s /mnt/nfs48/p1/ew/assembly-mecat/code/mecat.conf -p ew-mecat -d ew-mecat -pacbio-corrected /mnt/nfs48/p1/ew/assembly-mecat/run/ew.25x.fasta.fasta


<a id="org5c85570"></a>

# Polishing by PacBio reads (for FALCON assembly)


<a id="org233dbd1"></a>

## BLASR mapping

`blasr-falcon-for-arrow.sh`:

    set -eu
    date && hostname
    blasr='/mnt/nfs1/build/smrtlink_5.0.1/smrtcmds/bin/blasr'
    reads_list='/mnt/nfs48/p1/ew/data/subreads/list-bam.txt'
    i=$SLURM_ARRAY_TASK_ID
    reads=$(sed -n ${i}p $reads_list)
    ref='/mnt/nfs48/p1/ew/merge/p_ctg.fa'
    t=32
    outdir='/mnt/nfs48/p1/ew/merge/align-falcon'
    out="$outdir/$(basename $reads).blasr.bam"

    $blasr "$reads" $ref --nproc $t --out $out --bam
    echo "[$(date)] [i=$i] done blasr for $reads"

Submit jobs:

    sbatch -D $PWD -c32 --mem=60000 -a 1-15 -o /mnt/nfs1/slurm-log/blasr-%A_%a.out -e /mnt/nfs1/slurm-log/blasr-%A_%a.err blasr-falcon-for-arrow.sh


<a id="org7f260ec"></a>

## Sort and pbindex

`blasr-falcon-for-arrow-sort-bam.sh`:

    set -eu
    list='/mnt/nfs48/p1/ew/merge/align-falcon/list-blasr-bam.txt'
    i=$SLURM_ARRAY_TASK_ID
    bam=$(sed -n ${i}p $list)
    t=48
    outdir='/mnt/nfs48/p1/ew/merge/align-falcon'
    out="$outdir/$(basename $bam).sorted.bam"
    samtools='/mnt/nfs1/software/miniconda2/bin/samtools'
    venv='/mnt/nfs1/build/falcon/fc_env_171204/bin/activate'

    $samtools sort -@ $t -O bam -T /tmp -o $out $bam
    sleep 5
    rm -f $bam
    bash -c "source $venv; pbindex $out"
    echo "[$(date)] done: $out"

Submit jobs:

    sbatch -D $PWD -c48 --mem=70000 -a 1-15 -o /mnt/nfs1/slurm-log/blasr-%A_%a.out -e /mnt/nfs1/slurm-log/blasr-%A_%a.err blasr-falcon-for-arrow-sort-bam.sh


<a id="org31b74cd"></a>

## Run arrow

    cd /mnt/nfs48/p1/ew/merge/align-falcon
    ls /mnt/nfs48/p1/ew/merge/align-falcon >list-sorted-bam.fofn
    bash
    source /mnt/nfs1/falcon/fc_env_171104/bin/activate
    arrow -j 8 list-sorted-bam.fofn -r /mnt/nfs48/p1/ew/merge/p_ctg.fa -o t2.gff -o t2.fasta -o t2.fastq


<a id="orgc0f2f08"></a>

## Combine fasta generated by arrow

    cd /mnt/nfs48/p1/ew/merge/align-falcon/split-fasta
    cat *.fasta >../polished-falcon.fasta
    cat *.fastq | gzip -c >../polished-falcon.fastq.gz


<a id="orgb93b880"></a>

# Polishing by illumina reads (for FALCON assembly)

`pilon.sh`:

    #!/bin/bash
    set -eu
    addition=$1
    java=/mnt/nfs1/software/jre1.8.0_162/bin/java
    ref='/mnt/nfs48/p1/ew/merge/align-falcon/polished-falcon.fasta'
    bam_L004='/mnt/nfs48/p1/ew/data/nextomics-PE-reads/L004-sorted.bam'
    bam_L005='/mnt/nfs48/p1/ew/map-back-to-polished-contig/L005-sorted.bam'
    bam_W2='/mnt/nfs48/p1/ew/map-back-to-polished-contig/W2-sorted.bam'
    contig_id='/mnt/nfs48/p1/ew/merge/align-falcon/polished-falcon.fasta.id'
    line=$(expr $addition + ${SLURM_ARRAY_TASK_ID})
    targets=$(sed -n ${line}p $contig_id)
    mem=12
    t=$SLURM_CPUS_PER_TASK

    cd /mnt/nfs48/p1/ew/polish-pilon
    echo "[$(date)] [$(hostname)] begin"
    $java -Xmx${mem}G -jar /mnt/nfs1/software/ew/pilon-1.22.jar \
          --genome $ref \
          --frags $bam_L004 \
          --frags $bam_L005 \
          --frags $bam_W2 \
          --output pilon-$targets \
          --changes \
          --diploid \
          --targets $targets \
          --threads $t
    echo "[$(date)] [$(hostname)] end"

Total number of contigs: 16882.

Submit Pilon jobs:

    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 1000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 2000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 3000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 4000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 5000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 6000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 7000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 8000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 9000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 10000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 11000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 12000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 13000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 14000
    sbatch -c 4 --mem=10G -a 1-1000 -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 15000
    sbatch -c 4 --mem=10G -a 1-882  -o ./log/%A_%a.out -e ./log/%A_%a.err pilon.sh 16000

Cat Pilon outputs to single fasta: `ew-polished-pilon.fasta`.


<a id="orga5cb8c8"></a>

# Scaffolding by Hi-C reads

`hic-lachesis-mapping.sh`:

    #!/usr/bin/bash
    set -eux
    fq1=$1
    fq2=$2
    cpu=$3
    fq1_out=$(basename $fq1).sai
    fq2_out=$(basename $fq2).sai
    sampe_out=$(basename $fq1)-sorted.bam
    markdup_out=$(basename $fq1)-markdup.bam
    markdup_sorted_out=$(basename $fq1)-markdup-sorted.bam
    ref='/mnt/nfs48/p1/ew/polish-pilon/ew-polished-pilon.fasta'
    export PATH=/mnt/nfs1/software/miniconda2/bin:$PATH

    echo "[$(date)] [$(hostname)] processing $fq1 $fq2"
    bwa aln -t $cpu $ref $fq1 >$fq1_out
    bwa aln -t $cpu $ref $fq2 >$fq2_out

    bwa sampe \
        $ref \
        $fq1_out \
        $fq2_out \
        $fq1 \
        $fq2 \
        | samtools view -@ 8 -bS -F 4 -q 1 - \
        | samtools sort -n -@ $cpu -O bam -T /tmp - >$sampe_out

    rm -f $fq1_out $fq2_out
    perl /mnt/nfs1/build/LACHESIS/bin/PreprocessSAMs-v2.pl $sampe_out $ref
    ls -hl $sampe_out
    rm -f $sampe_out
    echo "[$(date)] [$(hostname)] done $fq1 (and its pair)"

`hic-lachesis-mapping-batch.sh`:

    set -eu
    logdir=$PWD
    cpu=16
    for f in $@; do
        f2=$(echo $f | sed 's/_R1/_R2/')
        sbatch -c$cpu --mem=16G -o $logdir/%j.out -e $logdir/%j.err hic-lachesis-mapping.sh $f $f2 $cpu
    done

Submit `hic-lachesis-mapping-batch.sh`:

    bash hic-lachesis-mapping.sh *_R1*.fastq.gz

`ew-all-data.ini`:

    SPECIES = ew
    OUTPUT_DIR = /mnt/nfs48/p1/ew/hi-c/lachesis/run
    DRAFT_ASSEMBLY_FASTA = /mnt/nfs48/p1/ew/polish-pilon/ew-polished-pilon.fasta
    SAM_DIR = /mnt/nfs48/p1/ew/hi-c/lachesis/hic-bam-for-lachesis
    SAM_FILES = HS180713-2_QY-25_S1_L003_R1_001.fastq000.fastq.gz-sorted.REduced.paired_only.bam \
                HS180713-2_QY-25_S1_L003_R1_001.fastq001.fastq.gz-sorted.REduced.paired_only.bam \
                HS180713-2_QY-25_S1_L003_R1_001.fastq002.fastq.gz-sorted.REduced.paired_only.bam \
                # ... other bam files ...
    RE_SITE_SEQ = GATC
    USE_REFERENCE = 0
    SIM_BIN_SIZE = 0
    DO_CLUSTERING = 1
    DO_ORDERING   = 1
    DO_REPORTING  = 1
    OVERWRITE_GLM = 0
    OVERWRITE_CLMS = 0
    CLUSTER_N = 36
    CLUSTER_CONTIGS_WITH_CENS = -1
    CLUSTER_MIN_RE_SITES = 25
    CLUSTER_MAX_LINK_DENSITY = 2
    CLUSTER_NONINFORMATIVE_RATIO = 3
    CLUSTER_DRAW_HEATMAP = 1
    CLUSTER_DRAW_DOTPLOT = 1
    ORDER_MIN_N_RES_IN_TRUNK = 15
    ORDER_MIN_N_RES_IN_SHREDS = 15
    ORDER_DRAW_DOTPLOTS = 1
    REPORT_EXCLUDED_GROUPS = -1
    REPORT_QUALITY_FILTER = 1
    REPORT_DRAW_HEATMAP = 1

`hic-lachesis-all-data-args.sh`:

    #!/usr/bin/bash
    trap exit INT
    set -eux -o pipefail
    outdir_dir=$(readlink -f $1)
    n=$2
    shred=$3                        # default: 15
    CLUSTER_MIN_RE_SITES=$4         # default: 25
    ORDER_MIN_N_RES_IN_TRUNK=$5     # default: 15
    ini_orig='ew-all-data.ini'
    ref='/mnt/nfs48/p1/ew/polish-pilon/ew-polished-pilon.fasta'
    prefix="ew-$n-$shred-$CLUSTER_MIN_RE_SITES-$ORDER_MIN_N_RES_IN_TRUNK"
    outdir=$outdir_dir/$prefix
    ini=$outdir/$prefix.ini
    mkdir -p $outdir
    cd $outdir
    sed -re "s/^CLUSTER_N = [0-9]+/CLUSTER_N = $n/;
             s|^OUTPUT_DIR = .+|OUTPUT_DIR = $outdir|;
             s/ORDER_MIN_N_RES_IN_SHREDS = [0-9]+/ORDER_MIN_N_RES_IN_SHREDS = $shred/;
             s/^CLUSTER_MIN_RE_SITES = [0-9]+/CLUSTER_MIN_RE_SITES = $CLUSTER_MIN_RE_SITES/;
             s/^ORDER_MIN_N_RES_IN_TRUNK = [0-9]+/ORDER_MIN_N_RES_IN_TRUNK = $ORDER_MIN_N_RES_IN_TRUNK/" \
        $ini_orig >$ini
    simg=$(ls -1 ~/software/ubuntu_*.simg | tail -n1)
    log_prefix=$prefix
    {
        echo "[$(date)] [$(hostname)]"
        singularity exec -B /mnt $simg /home/bio/bin/LACHESIS/run-Lachesis.sh $ini
        # /mnt/nfs1/build/LACHESIS/bin/Lachesis $ini
        [ -e REPORT.txt ] && mv REPORT.txt REPORT-n$n-shred-$shred.txt
        [ -e HiC_heatmap.jpg ] && mv HiC_heatmap.jpg $prefix.jpg
        echo "[$(date)] [$(hostname)]"
        # generate scaffold fasta
        singularity exec -B /mnt $simg perl /home/bio/bin/LACHESIS/bin/CreateScaffoldedFasta.pl $ref $outdir
        # perl /mnt/nfs1/build/LACHESIS/bin/CreateScaffoldedFasta.pl $ref $outdir
        echo "[$(date)] [$(hostname)]"
    } 1> >(tee -a $log_prefix.out) 2> >(tee -a $log_prefix.err)

Run LACHESIS:

    bash hic-lachesis-all-data-args.sh ./ew/hic/lachesis 43 15 50 100


<a id="org5ef3756"></a>

# Gap closing

`pbjelly-config.xml`:

    <jellyProtocol>
      <reference>/mnt/nfs48/p1/ew/gap-closing/Lachesis_assembly-43-15-50-100.fasta</reference>
      <outputDir>/mnt/nfs48/p1/ew/gap-closing/pbjelly-out</outputDir>
      <blasr>-minMatch 8 -sdpTupleSize 8 -minPctIdentity 75 -bestn 1 -nCandidates 10 -maxScore -500 -nproc 8 -noSplitSubreads</blasr>
      <input baseDir="/mnt/nfs48/p1/ew/subreads-fastq-split/">
        <job>m54143_170908_111957.subreads.fastq.001.fastq</job>
        <job>m54143_170908_111957.subreads.fastq.002.fastq</job>
        <job>m54143_170908_111957.subreads.fastq.003.fastq</job>
        <!-- <job>...other fastq files...</job> -->
      </input>
    </jellyProtocol>

`run-pbjelly.sh`:

    #!/bin/bash
    trap exit INT
    set -e
    xml='pbjelly-config.xml'
    export PATH=/home/bio/software/blasr-1.3.1-binary:$PATH
    export PATH=/home/bio/software/networkx-virtualenv/bin:$PATH
    export PATH=/home/bio/software/PBSuite_15.8.24/bin:$PATH
    export PATH=/home/bio/software/PBSuite_15.8.24/pbsuite/jelly:$PATH
    export PATH=/home/bio/software/PBSuite_15.8.24/pbsuite/utils:$PATH
    export PYTHONPATH=/home/bio/software/PBSuite_15.8.24:$PYTHONPATH
    export PYTHONPATH=/home/bio/software/networkx-virtualenv/lib/python2.7/site-packages:$PYTHONPATH
    Jelly.py setup $xml
    Jelly.py mapping $xml
    Jelly.py support $xml
    Jelly.py extraction $xml
    Jelly.py assembly $xml -x "--nproc=32"
    Jelly.py output $xml

Run pbjelly:

    bash run-pbjelly.sh
